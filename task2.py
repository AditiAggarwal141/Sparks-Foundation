# -*- coding: utf-8 -*-
"""TASK 2 Data Science and Business Analytics Internship at The Sparks Foundation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qn0NH-LwnkEtWaSbgHzdm4V7r7H3CdlN

**GRIP**- **THE SPARKS FOUNDATION**

**TASK-2:- PREDICTION USING UNSUPERVISED MACHINE LEARNING**

*The aim of this task is to predict the optimum number of clusters from the IRIS Dataset and represent it visually. 

AUTHOR:- ADITI AGGARWAL

**STEP-1-IMPORTING DATA**
"""

#importing dependencies
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.cluster import KMeans

#Import data 

df= pd.read_csv(r'/content/Iris.csv')  
df.head()

"""**STEP2-VISUALISING DATA**"""

#information of dataset
df.info()

#Checking the distribution of the target class

df.Species.value_counts()

#Descriptive Statistics

df.describe()

#Dropped unnecessary columns

df.drop("Id",inplace=True,axis=1)
df.drop("Species",inplace=True,axis=1)

"""**STEP 3- FINDING OPTIMUM NUMBER OF CLUSTERS**"""

# Calculating the within-cluster sum of square

within_cluster_sum_of_square = []
x = df.iloc[:, [0, 1, 2, 3]].values

clusters_range = range(1,15)
for k in clusters_range:
    km = KMeans(n_clusters=k)
    km = km.fit(df)
    within_cluster_sum_of_square.append(km.inertia_)

# Plotting the "within-cluster sum of square" against clusters range

plt.plot(clusters_range, within_cluster_sum_of_square, 'go--', color='red')
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('Within-cluster sum of square')
plt.grid()
plt.show()

"""**STEP 4- APPLYING KMEANS CLUSTERING ON DATA**"""

model = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
predictions = model.fit_predict(df)
predictions

"""**STEP 5- VISUALIZING THE CLUSTERS**"""

# Visualising the clusters 
plt.figure(figsize=(10,5))
plt.scatter(x[predictions == 0, 0], x[predictions == 0, 1], s = 50, c = 'orange', label = 'Iris-setosa')
plt.scatter(x[predictions == 1, 0], x[predictions == 1, 1], s = 50, c = 'purple', label = 'Iris-versicolour')
plt.scatter(x[predictions == 2, 0], x[predictions == 2, 1], s = 50, c = 'green', label = 'Iris-virginica')

# Plotting the cluster centers

plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:,1], s = 200, c = 'red', label = 'Centroids')
plt.legend()
plt.grid()
plt.show()